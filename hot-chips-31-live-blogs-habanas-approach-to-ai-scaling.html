<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Habana's Approach to AI Scaling -</title><meta name=robots content="index,follow,noarchive"><meta name=description content="09:21PM EDT - The final talk today at Hot Chips is from Habana, who is discussing its approach to how to scale AI compute.
09:21PM EDT - Goya and Gaudi
09:22PM EDT - Recapping Training vs Inference requirements

09:24PM EDT - Goya processor architecure

09:24PM EDT - 3 engines, RPC, GEMM, and DMA. Work Concurrently with shared SRAM
09:24PM EDT - TPC is VLIW SIMD core, C-programmable"><meta name=author content="Martina Birk"><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/app.css><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/an-old-hope.min.css><script defer src=https://assets.cdnweb.info/hugo/paper/js/highlight.min.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=preload as=image href=./theme.png><link rel=icon href=./favicon.ico><link rel=apple-touch-icon href=./apple-touch-icon.png><meta name=generator content="Hugo 0.98.0"><meta property="og:title" content="Habana's Approach to AI Scaling"><meta property="og:description" content="09:21PM EDT - The final talk today at Hot Chips is from Habana, who is discussing its approach to how to scale AI compute. 09:21PM EDT - Goya and Gaudi 09:22PM EDT - Recapping Training vs Inference requirements"><meta property="og:type" content="article"><meta property="og:url" content="/hot-chips-31-live-blogs-habanas-approach-to-ai-scaling.html"><meta property="article:section" content="post"><meta itemprop=name content="Habana's Approach to AI Scaling"><meta itemprop=description content="09:21PM EDT - The final talk today at Hot Chips is from Habana, who is discussing its approach to how to scale AI compute. 09:21PM EDT - Goya and Gaudi 09:22PM EDT - Recapping Training vs Inference requirements"><meta itemprop=wordCount content="669"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Habana's Approach to AI Scaling"><meta name=twitter:description content="09:21PM EDT - The final talk today at Hot Chips is from Habana, who is discussing its approach to how to scale AI compute. 09:21PM EDT - Goya and Gaudi 09:22PM EDT - Recapping Training vs Inference requirements"></head><body class=not-ready data-menu=true><header class=header><p class=logo><a class=site-name href=./index.html>JoltVibe</a><a class=btn-dark></a></p><script>let bodyClx=document.body.classList,btnDark=document.querySelector(".btn-dark"),sysDark=window.matchMedia("(prefers-color-scheme: dark)"),darkVal=localStorage.getItem("dark"),setDark=e=>{bodyClx[e?"add":"remove"]("dark"),localStorage.setItem("dark",e?"yes":"no")};setDark(darkVal?darkVal==="yes":sysDark.matches),requestAnimationFrame(()=>bodyClx.remove("not-ready")),btnDark.addEventListener("click",()=>setDark(!bodyClx.contains("dark"))),sysDark.addEventListener("change",e=>setDark(e.matches))</script><nav class=menu><a href=./sitemap.xml>Sitemap</a></nav></header><main class=main><article class=post-single><header class=post-title><p><span>Martina Birk</span></p><h1>Habana's Approach to AI Scaling</h1></header><section class=post-content><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_184445_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_184403_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212118 href=#><span class=lb_time>09:21PM EDT</span></a> - The final talk today at Hot Chips is from Habana, who is discussing its approach to how to scale AI compute.</p><p><a id=post0819212122 href=#><span class=lb_time>09:21PM EDT</span></a> - Goya and Gaudi</p><p><a id=post0819212202 href=#><span class=lb_time>09:22PM EDT</span></a> - Recapping Training vs Inference requirements</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182142_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212411 href=#><span class=lb_time>09:24PM EDT</span></a> - Goya processor architecure</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182354_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212428 href=#><span class=lb_time>09:24PM EDT</span></a> - 3 engines, RPC, GEMM, and DMA. Work Concurrently with shared SRAM</p><p><a id=post0819212439 href=#><span class=lb_time>09:24PM EDT</span></a> - TPC is VLIW SIMD core, C-programmable</p><p><a id=post0819212445 href=#><span class=lb_time>09:24PM EDT</span></a> - PCIe Gen 4.0 x16</p><p><a id=post0819212457 href=#><span class=lb_time>09:24PM EDT</span></a> - Two DDR4-2666 channels, built on TSMC 16</p><p><a id=post0819212508 href=#><span class=lb_time>09:25PM EDT</span></a> - Supports UINT8 to FP32</p><p><a id=post0819212519 href=#><span class=lb_time>09:25PM EDT</span></a> - Dedicated HW and TPC ISA for special function acceneration</p><p><a id=post0819212555 href=#><span class=lb_time>09:25PM EDT</span></a> - Have to adjust quantization to mix accuracy vs power</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182600_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212646 href=#><span class=lb_time>09:26PM EDT</span></a> - PCIe card - Software stack is more important.</p><p><a id=post0819212658 href=#><span class=lb_time>09:26PM EDT</span></a> - Habana is a software company that just happens to do hardware</p><p><a id=post0819212719 href=#><span class=lb_time>09:27PM EDT</span></a> - Graph compiler with built-in quantization engine</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182703_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212730 href=#><span class=lb_time>09:27PM EDT</span></a> - Multiple recipes can be loaded for the hardware</p><p><a id=post0819212801 href=#><span class=lb_time>09:28PM EDT</span></a> - Goya supports models trained on any processor: CPU, GPU, TPU, Gaudi etc</p><p><a id=post0819212837 href=#><span class=lb_time>09:28PM EDT</span></a> - Users can create custom layers and kernels</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182844_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212918 href=#><span class=lb_time>09:29PM EDT</span></a> - Still market leader since benchmarks made 11 months ago vs common CPU/GPU</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182931_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212948 href=#><span class=lb_time>09:29PM EDT</span></a> - New for today, natural language benchmark results</p><p><a id=post0819213004 href=#><span class=lb_time>09:30PM EDT</span></a> - Support BERT architecture on Goya</p><p><a id=post0819213019 href=#><span class=lb_time>09:30PM EDT</span></a> - GEMMs and TPCs are fully utilized</p><p><a id=post0819213027 href=#><span class=lb_time>09:30PM EDT</span></a> - Chip was designed long before BERT was invested</p><p><a id=post0819213029 href=#><span class=lb_time>09:30PM EDT</span></a> - invented</p><p><a id=post0819213039 href=#><span class=lb_time>09:30PM EDT</span></a> - High degree of accuracy when quantized</p><p><a id=post0819213044 href=#><span class=lb_time>09:30PM EDT</span></a> - Software managed SRAM</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183054_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213135 href=#><span class=lb_time>09:31PM EDT</span></a> - Now Gaudi, the training processor</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183121_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213150 href=#><span class=lb_time>09:31PM EDT</span></a> - Performance at Scale, high throughput at low batch size, high power efficiency</p><p><a id=post0819213207 href=#><span class=lb_time>09:32PM EDT</span></a> - Enable native ethernet scale out - on chip RDMA over Converged Ethernet</p><p><a id=post0819213225 href=#><span class=lb_time>09:32PM EDT</span></a> - Open Compute Project Accelerator Module: OAM = (OCP)AM</p><p><a id=post0819213237 href=#><span class=lb_time>09:32PM EDT</span></a> - Framework and ML compiler support, rich TPC Kernet Library</p><p><a id=post0819213257 href=#><span class=lb_time>09:32PM EDT</span></a> - Architecture looks similar to Goya</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183241_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213305 href=#><span class=lb_time>09:33PM EDT</span></a> - Networking has changed, memory has changed</p><p><a id=post0819213318 href=#><span class=lb_time>09:33PM EDT</span></a> - PCIe 4.0 x16, 4x8GB HBM</p><p><a id=post0819213325 href=#><span class=lb_time>09:33PM EDT</span></a> - 10x 100 GbE, or 20x50 GbE</p><p><a id=post0819213340 href=#><span class=lb_time>09:33PM EDT</span></a> - Supports UINT8 to FP32 and BF16</p><p><a id=post0819213417 href=#><span class=lb_time>09:34PM EDT</span></a> - SW supports profiling tools</p><p><a id=post0819213447 href=#><span class=lb_time>09:34PM EDT</span></a> - Only AI Training chip with RoCE v2</p><p><a id=post0819213509 href=#><span class=lb_time>09:35PM EDT</span></a> - NVIDIA was first to showcase RoCE v2 for AI, but they haven't implemented it yet</p><p><a id=post0819213608 href=#><span class=lb_time>09:36PM EDT</span></a> - NVIDIA GPU is much more complex with RoCE v2 support via Mellanox</p><p><a id=post0819213614 href=#><span class=lb_time>09:36PM EDT</span></a> - Gaudi integrates both</p><p><a id=post0819213632 href=#><span class=lb_time>09:36PM EDT</span></a> - Supports Lossless and Lossy fabrics</p><p><a id=post0819213641 href=#><span class=lb_time>09:36PM EDT</span></a> - Advanced congestion controls</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183432_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183525_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183548_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183715_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213740 href=#><span class=lb_time>09:37PM EDT</span></a> - Customers can buy OAM cards or an 8 card Server</p><p><a id=post0819213816 href=#><span class=lb_time>09:38PM EDT</span></a> - Server box has no CPU, up to customer to config to needed. Uses mini-SAS HD</p><p><a id=post0819213831 href=#><span class=lb_time>09:38PM EDT</span></a> - Ethernet connectivity for point-to-point links with non-blocking full mesh</p><p><a id=post0819213842 href=#><span class=lb_time>09:38PM EDT</span></a> - 3 ports per card for scale up</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183747_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213905 href=#><span class=lb_time>09:39PM EDT</span></a> - Can choose ratio of CPUs to Gaudi cards</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183849_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213931 href=#><span class=lb_time>09:39PM EDT</span></a> - Gaudi vs DGX</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183918_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819214037 href=#><span class=lb_time>09:40PM EDT</span></a> - Unlike DGX, do not force user to separate PCIe between management and scaleout. Gaudi offers separate PCIe ports</p><p><a id=post0819214103 href=#><span class=lb_time>09:41PM EDT</span></a> - PCIe card dual slot also available</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_184043_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819214105 href=#><span class=lb_time>09:41PM EDT</span></a> - HL-200</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_184117_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819214133 href=#><span class=lb_time>09:41PM EDT</span></a> - Data parallel possible, model parallel possible</p><p><a id=post0819214440 href=#><span class=lb_time>09:44PM EDT</span></a> - Can leapfrog performance over DGX-2 due to better connectivity. Can connect 64 gaudi chips with non-blocking throughput</p><p><a id=post0819214538 href=#><span class=lb_time>09:45PM EDT</span></a> - Q&A time</p><p><a id=post0819214645 href=#><span class=lb_time>09:46PM EDT</span></a> - Q: What type of quantization requires a processor? There is no quantization processor. There's a software engine that takes an FP32 model and can quantize to data types that are more efficient and gives the feedback on the accuracy</p><p><a id=post0819214740 href=#><span class=lb_time>09:47PM EDT</span></a> - Q: Can you comment on interconnectivity of GEMM? A: It's one functional unit.</p><p><a id=post0819214818 href=#><span class=lb_time>09:48PM EDT</span></a> - Q: What is the minimum viable for an IoT gateway? A: You can use a single card. You can put a gaudi in a single PCIe slot.</p><p><a id=post0819214833 href=#><span class=lb_time>09:48PM EDT</span></a> - That's a wrap for today. More talks tomorrow!</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH51g5VpZqGnpGKwqbXPrGRsaV2htrexjJujqJ%2BjYrWirsCnmKxlkaW9s7vAnJ9mrJ9irqp50pyYpaGenA%3D%3D</p></section><nav class=post-nav><a class=prev href=./dwight-eisenhower.html><span>←</span><span>Dwight Eisenhower movie reviews &amp;amp; film summaries</span></a>
<a class=next href=./is-daveed-diggs-playing-the-thing-in-the-mcus-fantastic-four.html><span>Is Daveed Diggs playing The Thing in the MCUs Fantastic Four?</span><span>→</span></a></nav></article></main><footer class=footer><p>&copy; 2024 <a href=./></a></p><p>Powered by <a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>️</p></footer><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>